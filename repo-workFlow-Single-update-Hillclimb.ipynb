{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import astroprov\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "\n",
    "import collections\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from astropy.io import ascii\n",
    "#from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import mysql.connector\n",
    "from pandas import DataFrame\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from mysql.connector import pooling\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/mysql-connector-java_8.0.16-1ubuntu16.04_all/usr/share/java/mysql-connector-java-8.0.16.jar  pyspark-shell'\n",
    "config = SparkConf().setAll([('spark.executor.cores', '6'),('spark.cores.max', '6'),('spark.driver.memory','1g'),('spark.executor.memory', '500m'),(\"spark.sql.execution.arrow.enabled\", \"true\")]) # (\"spark.sql.execution.arrow.enabled\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=App, master=local[*]) created by __init__ at <ipython-input-9-f19d620c11a2>:1 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f19d620c11a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'App'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/context.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/context.pyc\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    330\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 332\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=App, master=local[*]) created by __init__ at <ipython-input-9-f19d620c11a2>:1 "
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName='App',conf=config)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mags = [7,6,5,4,3,2,1]\n",
    "for mag in mags:\n",
    "    dataframe_mysql = sqlContext.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://localhost/Kepler\").option(\"driver\", \"com.mysql.jdbc.Driver\").option(\"dbtable\", \"starlist_{}\".format(mag)).option(\"user\", \"mj1e16\").option(\"password\", \"[sqlT1G3R]\").load()\n",
    "    dataframe_mysql.registerTempTable('starlist_{}'.format(mag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def innerJoin(tableName,totGross,variableList,mag,diffSize=1,xlength=1015.,ylength=1085.):\n",
    "    nsegs = 4\n",
    "    #mag = variableList[6]\n",
    "    temptableName = tableName[0:5]+tableName[-1]\n",
    "    OGtemptableName = 'original'\n",
    "    OGdf = sqlContext.sql(\"SELECT NUMBER, MAG_BEST, X_IMAGE, Y_IMAGE FROM {0} INNER JOIN starlist_{1} ON {0}.X_IMAGE BETWEEN starlist_{1}.X_POS_MIN AND starlist_{1}.X_POS_MAX AND {0}.Y_IMAGE BETWEEN starlist_{1}.Y_POS_MIN AND starlist_{1}.Y_POS_MAX\".format(OGtemptableName,abs(mag)))\n",
    "    OGdf.registerTempTable(OGtemptableName+'match')\n",
    "    sqlContext.cacheTable(OGtemptableName+'match')\n",
    "    OGtotNumber = OGdf.count()\n",
    "    \n",
    "    df = sqlContext.sql(\"SELECT NUMBER, MAG_BEST, X_IMAGE, Y_IMAGE FROM {0} INNER JOIN starlist_{1} ON {0}.X_IMAGE BETWEEN starlist_{1}.X_POS_MIN AND starlist_{1}.X_POS_MAX AND {0}.Y_IMAGE BETWEEN starlist_{1}.Y_POS_MIN AND starlist_{1}.Y_POS_MAX\".format(temptableName,abs(mag)))\n",
    "    df.registerTempTable(temptableName+'match')\n",
    "    sqlContext.cacheTable(temptableName+'match')\n",
    "    totNumber = df.count()\n",
    "    #print('tot',totNumber)\n",
    "    \n",
    "    xsegment = xlength/nsegs\n",
    "    ysegment = ylength/nsegs\n",
    "    score = 0\n",
    "    #totSeg = []\n",
    "    #df.write.format('jdbc').options(url='jdbc:mysql://localhost/Kepler',driver='com.mysql.jdbc.Driver',dbtable='result_{}'.format(tableName),user='mj1e16',password='[sqlT1G3R]').mode('append').save()\n",
    "    for xsegs in range(nsegs):\n",
    "        xmin = int(xsegs*xsegment)+15\n",
    "        xmax = int(xmin+xsegment)+15\n",
    "        for ysegs in range(nsegs):\n",
    "            ymin = int(ysegs*ysegment)+15\n",
    "            ymax = int(ymin+ysegment)+15\n",
    "            \n",
    "            OGdf = sqlContext.sql(\"SELECT NUMBER FROM {0} WHERE {0}.X_IMAGE BETWEEN {1} AND {2} AND {0}.Y_IMAGE BETWEEN {3} AND {4}\".format(OGtemptableName+'match',xmin,xmax,ymin,ymax))\n",
    "            OGnumber = OGdf.count()\n",
    "            df = sqlContext.sql(\"SELECT NUMBER FROM {0} WHERE {0}.X_IMAGE BETWEEN {1} AND {2} AND {0}.Y_IMAGE BETWEEN {3} AND {4}\".format(temptableName+'match',xmin,xmax,ymin,ymax))\n",
    "            number = df.count()\n",
    "            simulated = number-OGnumber\n",
    "            score += abs(simulated-62)\n",
    "            variableList.append(simulated)\n",
    "            \n",
    "#             dftot = sqlContext.sql(\"SELECT NUMBER FROM {0} WHERE {0}.X_IMAGE BETWEEN {1} AND {2} AND {0}.Y_IMAGE BETWEEN {3} AND {4}\".format(temptableName,xmin,xmax,ymin,ymax))\n",
    "#             number = df.count()\n",
    "#             #variableList.append(number)\n",
    "#             totSeg.append(number)\n",
    "\n",
    "            # need to create some place to write to\n",
    "\n",
    "    \n",
    "    \n",
    "#    variableList.extend(totSeg)\n",
    "    #astroprov.provcall([tableName,'starlist_{}'.format(abs(mag))],['result_{}'.format(tableName)],\"innerJoin_Python2Python_SQ_tmpl.provn\",\"innerJoin\",provDir)\n",
    "    \n",
    "    sqlContext.uncacheTable(temptableName+'match')\n",
    "    sqlContext.dropTempTable(temptableName+'match')\n",
    "    sqlContext.uncacheTable(OGtemptableName+'match')\n",
    "    sqlContext.dropTempTable(OGtemptableName+'match')\n",
    "    sqlContext.uncacheTable(temptableName)\n",
    "    sqlContext.dropTempTable(temptableName)\n",
    "    sqlContext.uncacheTable(OGtemptableName)\n",
    "    sqlContext.dropTempTable(OGtemptableName)\n",
    "    variableList.append(totNumber)\n",
    "    variableList.append(totGross)\n",
    "    variableList.append(OGtotNumber)\n",
    "    variableList.append(score)\n",
    "    variableTuple = tuple(variableList)\n",
    "    #print(variableTuple)\n",
    "    return [variableTuple,score]\n",
    "\n",
    "\n",
    "def makeConfig(valList,tableName='table',defaultDir='/home/mj1e16/sextractor/sextractor-master/config/',attributeList=['DETECT_THRESH','DETECT_MINAREA','FILTER_NAME']):\n",
    "    \n",
    "    with open(defaultDir+'/default.sex','r') as f:\n",
    "        data  = f.read()\n",
    "    for x in range(len(valList)):\n",
    "        nameLoc = data.find(attributeList[x]) + len(attributeList[x])\n",
    "        endLoc = data[nameLoc:].find('#') + nameLoc\n",
    "        newData = data[:nameLoc] + ' '+str(valList[x])+' ' + data[endLoc:]\n",
    "        data = newData\n",
    "    \n",
    "    cname = 'CATALOG_NAME'\n",
    "    catName = 'test1.cat'\n",
    "    confName = 'default_1.sex'\n",
    "    nameLoc = data.find(cname) + len(cname)\n",
    "    endLoc = data[nameLoc:].find('#') + nameLoc\n",
    "    newData = data[:nameLoc] + ' ' +catName+ ' ' + data[endLoc:]\n",
    "    data = newData\n",
    "\n",
    "    cname = 'PARAMETERS_NAME'\n",
    "    nameLoc = data.find(cname) + len(cname)\n",
    "    endLoc = data[nameLoc:].find('#') + nameLoc\n",
    "    newData = data[:nameLoc] + ' autodefault.param ' + data[endLoc:]\n",
    "    \n",
    "    #print(newData)\n",
    "    with open(defaultDir+confName,'w') as f:\n",
    "        f.write(newData)\n",
    "    return(confName,tableName,catName)\n",
    "\n",
    "def findObjects(confName,tableName,catName,defaultDir='/home/mj1e16/sextractor/sextractor-master/config/',imagename='/home/mj1e16/iraf/editedImage5000.fits',original='no'):\n",
    "    \n",
    "    os.chdir(defaultDir)\n",
    "    subprocess.call(['sex',imagename,'-c',confName])\n",
    "    assoc = Table.read(catName,format='ascii.sextractor')\n",
    "    df = assoc.to_pandas()\n",
    "    df2 = df[df['MAG_BEST'] != 99.0000]\n",
    "    df_spark = sqlContext.createDataFrame(df2)\n",
    "    temptableName = tableName[0:5]+tableName[-1]\n",
    "    if original == 'yes':\n",
    "        temptableName = 'original'\n",
    "    df_spark.registerTempTable(temptableName)\n",
    "    totGross = df_spark.count()\n",
    "    sqlContext.cacheTable(temptableName)\n",
    "\n",
    "    return totGross\n",
    "\n",
    "def alltogethernow(valList,tableName,IMAGE,variableList,originalImage,mag,atList):\n",
    "    Names = makeConfig(valList,tableName=tableName,attributeList=atList)\n",
    "    totGrossOriginal = findObjects(Names[0],Names[1],Names[2],imagename=originalImage,original='yes')\n",
    "    totGross = findObjects(Names[0],Names[1],Names[2],imagename=IMAGE) # confName tabName catname\n",
    "    finalTuple = innerJoin(Names[1],totGross,variableList,mag)\n",
    "    return finalTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hotpantsQuality(image):\n",
    "    hdu = fits.open(image)\n",
    "    imData = hdu[0].data\n",
    "    imData = abs(imData)\n",
    "    totVal = sum(imData)\n",
    "    totVal = sum(totVal)\n",
    "    return totVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valList = [np.linspace(1,10,10),np.linspace(1,9,9),['gauss_1.5_3x3.conv','gauss_2.0_3x3.conv','gauss_2.0_5x5.conv',\n",
    "                                                    'gauss_2.5_5x5.conv','gauss_3.0_5x5.conv','gauss_3.0_7x7.conv',\n",
    "                                                    'gauss_4.0_7x7.conv','gauss_5.0_9x9.conv','mexhat_1.5_5x5.conv',\n",
    "                                                    'mexhat_2.0_7x7.conv','mexhat_2.5_7x7.conv','mexhat_3.0_9x9.conv',\n",
    "                                                    'mexhat_4.0_9x9.conv','mexhat_5.0_11x11.conv','tophat_1.5_3x3.conv',\n",
    "                                                    'tophat_2.0_3x3.conv','tophat_2.5_3x3.conv','tophat_3.0_3x3.conv',\n",
    "                                                    'tophat_4.0_5x5.conv','tophat_5.0_5x5.conv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateImage(valList,simImage,OGImage,ccd,median,norm,minmag,smallName='newRun',atList=['DETECT_THRESH','DETECT_MINAREA','FILTER_NAME']):\n",
    "    \n",
    "    finalTableTuples = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for x0 in range(len(valList[0])):\n",
    "        for x1 in range(len(valList[1])):\n",
    "                name = smallName+'_'+str(x0)+'_'+str(x1)+'_'\n",
    "                for x2 in range(len(valList[2])):\n",
    "                    variableList = [float(valList[0][x0]),float(valList[1][x1]),valList[2][x2],ccd,median,minmag,norm]\n",
    "                    fullname = name+str(x2)\n",
    "                    fullValList = [valList[0][x0],valList[1][x1],valList[2][x2]]\n",
    "                    print(fullname)\n",
    "                    try:\n",
    "                        alltogethernowResults = alltogethernow(fullValList,tableName=fullname,IMAGE=simImage,variableList=variableList,originalImage=OGImage,mag=minmag,atList=atList)\n",
    "                        finalTableTuples.append(alltogethernowResults[0])\n",
    "                        score = alltogethernowResults[1]\n",
    "                    except RuntimeError:\n",
    "                        with open('redos','a') as f:\n",
    "                            bigString = simImage+','+str(fullname)+','+str(fullValList)\n",
    "                            f.write(bigString)\n",
    "                        print('Redo with valList = ',fullValList)\n",
    "                        pass\n",
    "\n",
    "    print(finalTableTuples)\n",
    "    rdd = sc.parallelize(finalTableTuples)\n",
    "    kepler = rdd.map(lambda x: Row(detectThresh=x[0],detectMinarea=x[1],filterName=x[2],ccd=x[3],median=x[4],medianQuality=x[5],\n",
    "                                   minmag=x[6], xy_0=int(x[7]),xy_1=int(x[8]),xy_2=int(x[9]),xy_3=int(x[10]),xy_4=int(x[11]),\n",
    "                                   xy_5=int(x[12]),xy_6=int(x[13]),xy_7=int(x[14]),xy_8=int(x[15]),xy_9=int(x[16]),xy_10=int(x[17]),\n",
    "                                   xy_11=int(x[18]),xy_12=int(x[19]),xy_13=int(x[20]),xy_14=int(x[21]),xy_15=int(x[22]),\n",
    "                                   totNum=int(x[23]),totGross=int(x[24]),OGtot=int(x[25]),OGtotGross=int(x[26]),score=int(x[27])))\n",
    "\n",
    "    schemaKepler = sqlContext.createDataFrame(kepler)\n",
    "    #print('finalResults_{}_{}_{}'.format(ccd,median,minmag))\n",
    "    schemaKepler.write.format('jdbc').options(url='jdbc:mysql://localhost/Kepler',driver='com.mysql.jdbc.Driver',dbtable='finalResultsNewRun_{}_{}_{}'.format(ccd,median,abs(minmag)),user='mj1e16',password='[sqlT1G3R]').mode('append').save()\n",
    "    \n",
    "    print(time.time()-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneSettingEvaluate(valList,simImage,OGImage,ccd,median,norm,minmag,smallName='newRun',starting=[0,0,0],atList=['DETECT_THRESH','DETECT_MINAREA','FILTER_NAME']):\n",
    "    \n",
    "    fullname = smallName+'_'+str(starting[0])+'_'+str(starting[1])+'_'+str(starting[2])               \n",
    "    variableList = [float(valList[0][starting[0]]),float(valList[1][starting[1]]),valList[2][starting[2]],ccd,median,minmag,norm]\n",
    "    fullValList = [valList[0][starting[0]],valList[1][starting[1]],valList[2][starting[2]]]\n",
    "    print(fullname)\n",
    "    print(starting)\n",
    "    try:\n",
    "        alltogethernowResults = alltogethernow(fullValList,tableName=fullname,IMAGE=simImage,variableList=variableList,originalImage=OGImage,mag=minmag,atList=atList)\n",
    "        finalTableTuples = alltogethernowResults[0]\n",
    "        baseScore = alltogethernowResults[1]\n",
    "    except RuntimeError:\n",
    "        with open('redos','a') as f:\n",
    "            bigString = simImage+','+str(fullname)+','+str(fullValList)\n",
    "            f.write(bigString)\n",
    "            basescore = -1\n",
    "        print('Redo with valList = ',fullValList)\n",
    "        pass\n",
    "    print(baseScore)\n",
    "    return [finalTableTuples,baseScore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluateImageHillClimbVersionOne(valList,simImage,OGImage,ccd,median,norm,minmag,smallName='newRun',atList=['DETECT_THRESH','DETECT_MINAREA','FILTER_NAME'],starting=[0,0,0]):\n",
    "    \n",
    "#     finalTableTuples = []\n",
    "#     t0 = time.time()\n",
    "#     scores = []\n",
    "    \n",
    "#     for loop in range(2):\n",
    "#         for x in range(len(valList)):\n",
    "#             scorePerVal = []\n",
    "#             for y in range(len(valList[x])):\n",
    "#                 starting[x] = y\n",
    "#                 fullname = smallName+'_'+str(starting[0])+'_'+str(starting[1])+'_'+str(starting[2])                \n",
    "#                 variableList = [float(valList[0][starting[0]]),float(valList[1][starting[1]]),valList[2][starting[2]],ccd,median,minmag,norm]\n",
    "#                 fullValList = [valList[0][starting[0]],valList[1][starting[1]],valList[2][starting[2]]]\n",
    "#                 print(starting)\n",
    "#                 print(fullname)\n",
    "#                 try:\n",
    "#                     alltogethernowResults = alltogethernow(fullValList,tableName=fullname,IMAGE=simImage,variableList=variableList,originalImage=OGImage,mag=minmag,atList=atList)\n",
    "#                     finalTableTuples.append(alltogethernowResults[0])\n",
    "#                     scorePerVal.append(alltogethernowResults[1])\n",
    "#                 except RuntimeError:\n",
    "#                     with open('redos','a') as f:\n",
    "#                         bigString = simImage+','+str(fullname)+','+str(fullValList)\n",
    "#                         f.write(bigString)\n",
    "#                         scorePerVal.append(-1)\n",
    "#                     print('Redo with valList = ',fullValList)\n",
    "#                     pass\n",
    "#             goodScores = [sco for sco in scorePerVal if x >= 0]\n",
    "#             best = scorePerVal.index(min(goodScores))\n",
    "#             starting[x] = best\n",
    "\n",
    "#     print(finalTableTuples)\n",
    "#     rdd = sc.parallelize(finalTableTuples)\n",
    "#     kepler = rdd.map(lambda x: Row(detectThresh=x[0],detectMinarea=x[1],filterName=x[2],ccd=x[3],median=x[4],medianQuality=x[5],\n",
    "#                                    minmag=x[6], xy_0=int(x[7]),xy_1=int(x[8]),xy_2=int(x[9]),xy_3=int(x[10]),xy_4=int(x[12]),\n",
    "#                                    xy_5=int(x[12]),xy_6=int(x[13]),xy_7=int(x[14]),xy_8=int(x[15]),xy_9=int(x[16]),xy_10=int(x[17]),\n",
    "#                                    xy_11=int(x[18]),xy_12=int(x[19]),xy_13=int(x[20]),xy_14=int(x[21]),xy_15=int(x[22]),totNum=int(x[23]),totGross=int(x[24]),OGtotGross=int(x[25])))\n",
    "\n",
    "#     schemaKepler = sqlContext.createDataFrame(kepler)\n",
    "#     #print('finalResults_{}_{}_{}'.format(ccd,median,minmag))\n",
    "#     schemaKepler.write.format('jdbc').options(url='jdbc:mysql://localhost/Kepler',driver='com.mysql.jdbc.Driver',dbtable='finalResultsNewRun_{}_{}_{}'.format(ccd,median,abs(minmag)),user='mj1e16',password='[sqlT1G3R]').mode('append').save()\n",
    "    \n",
    "#     print(time.time()-t0)\n",
    "#     return starting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateImageHillClimbVersionOne(valList,simImage,OGImage,ccd,median,norm,minmag,smallName='newRun',atList=['DETECT_THRESH','DETECT_MINAREA','FILTER_NAME'],starting=[0,0,0]):\n",
    "    \n",
    "    finalTableTuples = []\n",
    "    t0 = time.time()\n",
    "    scores = []\n",
    "    \n",
    "    startingBest = 10**10\n",
    "    best = 10**9\n",
    "    \n",
    "    while startingBest > best:\n",
    "        startingBest = best\n",
    "        for x in range(len(valList)):\n",
    "            scorePerVal = []\n",
    "            for y in range(len(valList[x])):\n",
    "                starting[x] = y\n",
    "                baseEvaluate = oneSettingEvaluate(valList,simImage,OGImage,ccd,median,norm,minmag,smallName=smallName,starting=starting,atList=atList)\n",
    "                finalTableTuples.append(baseEvaluate[0])\n",
    "                scorePerVal.append(baseEvaluate[1])\n",
    "\n",
    "            goodScores = [sco for sco in scorePerVal if x >= 0]\n",
    "            best = scorePerVal.index(min(goodScores))\n",
    "            bestList = [i for i, val in enumerate(goodScores) if val == min(goodScores)]\n",
    "            if len(bestList) == 1:\n",
    "                best = bestList[0]\n",
    "            else:\n",
    "                best = int(np.median(bestList))\n",
    "            starting[x] = best\n",
    "            print(scorePerVal)\n",
    "\n",
    "    print(finalTableTuples)\n",
    "    \n",
    "    rdd = sc.parallelize(finalTableTuples)\n",
    "    kepler = rdd.map(lambda x: Row(detectThresh=x[0],detectMinarea=x[1],filterName=x[2],ccd=x[3],median=x[4],medianQuality=x[5],\n",
    "                                   minmag=x[6], xy_0=int(x[7]),xy_1=int(x[8]),xy_2=int(x[9]),xy_3=int(x[10]),xy_4=int(x[11]),\n",
    "                                   xy_5=int(x[12]),xy_6=int(x[13]),xy_7=int(x[14]),xy_8=int(x[15]),xy_9=int(x[16]),xy_10=int(x[17]),\n",
    "                                   xy_11=int(x[18]),xy_12=int(x[19]),xy_13=int(x[20]),xy_14=int(x[21]),xy_15=int(x[22]),\n",
    "                                   totNum=int(x[23]),totGross=int(x[24]),OGtot=int(x[25]),OGtotGross=int(x[26]),score=int(x[27])))\n",
    "\n",
    "    schemaKepler = sqlContext.createDataFrame(kepler)\n",
    "    #print('finalResults_{}_{}_{}'.format(ccd,median,minmag))\n",
    "    schemaKepler.write.format('jdbc').options(url='jdbc:mysql://localhost/Kepler',driver='com.mysql.jdbc.Driver',dbtable='finalResultsSimpleLoop_{}_{}_{}'.format(ccd,median,abs(minmag)),user='mj1e16',password='[sqlT1G3R]').mode('append').save()\n",
    "    \n",
    "    print(time.time()-t0)\n",
    "    return starting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateImageHillClimbVersionTwo(valList,simImage,OGImage,ccd,median,norm,minmag,smallName='newRun',starting=[0,0,0],atList=['DETECT_THRESH','DETECT_MINAREA','FILTER_NAME']):\n",
    "    \n",
    "    finalTableTuples = []\n",
    "    t0 = time.time()\n",
    "    scores = []\n",
    "    \n",
    "    baseEvaluate = oneSettingEvaluate(valList,simImage,OGImage,ccd,median,norm,minmag,smallName=smallName,starting=starting,atList=atList)\n",
    "    finalTableTuples.append(baseEvaluate[0])\n",
    "    baseScore = baseEvaluate[1]\n",
    "    startScore = baseScore + 1\n",
    "    \n",
    "    plusMinus = [-1,1]\n",
    "    while baseScore < startScore:\n",
    "        startScore = baseScore\n",
    "        for x in range(len(valList)):\n",
    "            for y in plusMinus:\n",
    "                delta = -1\n",
    "                while delta < 0:\n",
    "                    minus = [z for z in starting]\n",
    "                    minus[x] += y\n",
    "                    if 0 < minus[x] < len(valList[x]):\n",
    "                        minusEvaluate = oneSettingEvaluate(valList,simImage,OGImage,ccd,median,norm,minmag,smallName=smallName,starting=minus,atList=atList)\n",
    "                        finalTableTuples.append(minusEvaluate[0])\n",
    "                        minusScore = minusEvaluate[1]\n",
    "\n",
    "                        delta = minusScore - baseScore\n",
    "\n",
    "                        randomVals = [random.randint(0,len(valList[0])-1),random.randint(0,len(valList[1])-1),random.randint(0,len(valList[2])-1)]\n",
    "                        randomEvaluate = oneSettingEvaluate(valList,simImage,OGImage,ccd,median,norm,minmag,smallName=smallName,starting=randomVals,atList=atList)\n",
    "                        finalTableTuples.append(randomEvaluate[0])\n",
    "                        randomScore = randomEvaluate[1]\n",
    "\n",
    "                        if randomScore < baseScore:\n",
    "                            starting = randomVals\n",
    "                            delta = randomScore - baseScore\n",
    "                            baseScore = randomScore\n",
    "\n",
    "                        elif minusScore < baseScore:\n",
    "                            starting = minus\n",
    "                            baseScore = minusScore\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                \n",
    "\n",
    "    print(finalTableTuples)\n",
    "    print(baseScore)\n",
    "    print(starting)\n",
    "    rdd = sc.parallelize(finalTableTuples)\n",
    "    kepler = rdd.map(lambda x: Row(detectThresh=x[0],detectMinarea=x[1],filterName=x[2],ccd=x[3],median=x[4],medianQuality=x[5],\n",
    "                                   minmag=x[6], xy_0=int(x[7]),xy_1=int(x[8]),xy_2=int(x[9]),xy_3=int(x[10]),xy_4=int(x[11]),\n",
    "                                   xy_5=int(x[12]),xy_6=int(x[13]),xy_7=int(x[14]),xy_8=int(x[15]),xy_9=int(x[16]),xy_10=int(x[17]),\n",
    "                                   xy_11=int(x[18]),xy_12=int(x[19]),xy_13=int(x[20]),xy_14=int(x[21]),xy_15=int(x[22]),\n",
    "                                   totNum=int(x[23]),totGross=int(x[24]),OGtot=int(x[25]),OGtotGross=int(x[26]),score=int(x[27])))\n",
    "\n",
    "    schemaKepler = sqlContext.createDataFrame(kepler)\n",
    "    #print('finalResults_{}_{}_{}'.format(ccd,median,minmag))\n",
    "    schemaKepler.write.format('jdbc').options(url='jdbc:mysql://localhost/Kepler',driver='com.mysql.jdbc.Driver',dbtable='finalResultsHillClimb_{}_{}_{}'.format(ccd,median,abs(minmag)),user='mj1e16',password='[sqlT1G3R]').mode('append').save()\n",
    "    \n",
    "    print(time.time()-t0)\n",
    "    return starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sqlContext.cacheTable('starlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sqlContext.sql('DROP TABLE IF EXISTS finalResults_44_1')\n",
    "#valList = [[1.],[1.],[8.],[3.]]\n",
    "#valList = [np.linspace(1,2,2),np.linspace(1,2,2),[8.],[3.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ccd = [44,63,79]\n",
    "# median = [0,1,2]\n",
    "# mags = np.linspace(-7,-1,7)\n",
    "\n",
    "#ccd = [44] #,63,79]\n",
    "ccd = [44]\n",
    "median = [1]\n",
    "mags = [-7,-6,-5,-4,-3,-2,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128.10734802244414, 1.0, 1.207334982887684]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "norms = []\n",
    "for inc,c in enumerate(ccd):\n",
    "    totVals = []\n",
    "    for x in range(3):\n",
    "        totVals.append(hotpantsQuality('/home/mj1e16/Simages/diff_{}_{}.fits'.format(c,x)))\n",
    "    norms.append([float(y/totVals[1]) for y in totVals])\n",
    "print(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRun5_44_1_-7_4_6_12\n",
      "[4, 6, 12]\n",
      "148\n",
      "newRun5_44_1_-7_3_6_12\n",
      "[3, 6, 12]\n",
      "146\n",
      "newRun5_44_1_-7_1_6_4\n",
      "[1, 6, 4]\n",
      "137\n",
      "newRun5_44_1_-7_2_6_4\n",
      "[2, 6, 4]\n",
      "137\n",
      "newRun5_44_1_-7_8_3_2\n",
      "[8, 3, 2]\n",
      "145\n",
      "newRun5_44_1_-7_1_5_4\n",
      "[1, 5, 4]\n",
      "138\n",
      "newRun5_44_1_-7_5_0_7\n",
      "[5, 0, 7]\n",
      "144\n",
      "newRun5_44_1_-7_1_7_4\n",
      "[1, 7, 4]\n",
      "137\n",
      "newRun5_44_1_-7_0_1_14\n",
      "[0, 1, 14]\n",
      "123\n",
      "newRun5_44_1_-7_0_2_14\n",
      "[0, 2, 14]\n",
      "128\n",
      "newRun5_44_1_-7_0_1_18\n",
      "[0, 1, 18]\n",
      "148\n",
      "newRun5_44_1_-7_0_1_13\n",
      "[0, 1, 13]\n",
      "141\n",
      "newRun5_44_1_-7_7_7_3\n",
      "[7, 7, 3]\n",
      "137\n",
      "newRun5_44_1_-7_0_1_15\n",
      "[0, 1, 15]\n",
      "143\n",
      "newRun5_44_1_-7_3_6_17\n",
      "[3, 6, 17]\n",
      "141\n",
      "newRun5_44_1_-7_1_1_14\n",
      "[1, 1, 14]\n",
      "129\n",
      "newRun5_44_1_-7_7_6_0\n",
      "[7, 6, 0]\n",
      "152\n",
      "newRun5_44_1_-7_0_2_14\n",
      "[0, 2, 14]\n",
      "128\n",
      "newRun5_44_1_-7_7_6_10\n",
      "[7, 6, 10]\n",
      "184\n",
      "newRun5_44_1_-7_0_1_13\n",
      "[0, 1, 13]\n",
      "141\n",
      "newRun5_44_1_-7_2_4_10\n",
      "[2, 4, 10]\n",
      "158\n",
      "newRun5_44_1_-7_0_1_15\n",
      "[0, 1, 15]\n",
      "143\n",
      "newRun5_44_1_-7_1_3_17\n",
      "[1, 3, 17]\n",
      "142\n",
      "[(5.0, 7.0, 'mexhat_4.0_9x9.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 65, 66, 47, 68, 64, 68, 50, 64, 48, 59, 30, 69, 58, 46, 47, 897, 1306, 0, 148), (4.0, 7.0, 'mexhat_4.0_9x9.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 65, 66, 49, 68, 64, 68, 50, 64, 48, 59, 30, 69, 58, 46, 47, 899, 1401, 0, 146), (2.0, 7.0, 'gauss_3.0_5x5.conv', 'ccd_44', 'median_1', -7, 1.0, 67, 63, 65, 48, 66, 62, 65, 48, 64, 50, 57, 29, 67, 58, 46, 46, 877, 2117, 1, 137), (3.0, 7.0, 'gauss_3.0_5x5.conv', 'ccd_44', 'median_1', -7, 1.0, 67, 63, 65, 48, 66, 62, 65, 48, 64, 50, 57, 29, 67, 58, 46, 46, 877, 1589, 1, 137), (9.0, 4.0, 'gauss_2.0_5x5.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 65, 67, 50, 68, 64, 68, 50, 64, 50, 59, 27, 68, 59, 46, 47, 900, 1327, 0, 145), (2.0, 6.0, 'gauss_3.0_5x5.conv', 'ccd_44', 'median_1', -7, 1.0, 67, 63, 65, 48, 66, 62, 65, 48, 64, 50, 57, 29, 67, 58, 45, 46, 877, 2285, 2, 138), (6.0, 1.0, 'gauss_5.0_9x9.conv', 'ccd_44', 'median_1', -7, 1.0, 64, 61, 63, 47, 63, 58, 63, 48, 62, 48, 56, 27, 65, 56, 37, 46, 840, 1052, 0, 144), (2.0, 8.0, 'gauss_3.0_5x5.conv', 'ccd_44', 'median_1', -7, 1.0, 67, 63, 65, 48, 66, 62, 65, 48, 64, 50, 57, 29, 67, 58, 46, 46, 877, 1994, 1, 137), (1.0, 2.0, 'tophat_1.5_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 67, 62, 66, 50, 67, 64, 66, 49, 62, 52, 57, 33, 68, 60, 52, 46, 922, 20526, 23, 123), (1.0, 3.0, 'tophat_1.5_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 64, 66, 50, 67, 64, 66, 49, 63, 52, 57, 32, 69, 60, 54, 46, 921, 14120, 14, 128), (1.0, 2.0, 'tophat_4.0_5x5.conv', 'ccd_44', 'median_1', -7, 1.0, 66, 63, 65, 47, 66, 61, 65, 48, 63, 50, 56, 27, 67, 55, 41, 46, 868, 6414, 9, 148), (1.0, 2.0, 'mexhat_5.0_11x11.conv', 'ccd_44', 'median_1', -7, 1.0, 66, 63, 64, 47, 66, 62, 65, 48, 61, 49, 56, 26, 67, 59, 45, 45, 873, 4695, 7, 141), (8.0, 8.0, 'gauss_2.5_5x5.conv', 'ccd_44', 'median_1', -7, 1.0, 67, 63, 65, 48, 66, 62, 66, 48, 64, 50, 57, 29, 67, 59, 46, 46, 879, 1119, 0, 137), (1.0, 2.0, 'tophat_2.0_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 68, 63, 66, 50, 67, 63, 65, 49, 62, 48, 57, 26, 69, 57, 48, 45, 906, 14535, 23, 143), (4.0, 7.0, 'tophat_3.0_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 63, 65, 48, 68, 64, 68, 50, 66, 50, 59, 31, 68, 59, 46, 47, 898, 1730, 0, 141), (2.0, 2.0, 'tophat_1.5_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 68, 65, 66, 50, 68, 64, 65, 50, 64, 51, 57, 32, 69, 60, 54, 46, 921, 12427, 13, 129), (8.0, 7.0, 'gauss_1.5_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 65, 67, 50, 68, 64, 68, 50, 66, 52, 59, 30, 69, 58, 38, 47, 895, 1182, 0, 152), (1.0, 3.0, 'tophat_1.5_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 64, 66, 50, 67, 64, 66, 49, 63, 52, 57, 32, 69, 60, 54, 46, 921, 14120, 14, 128), (8.0, 7.0, 'mexhat_2.5_7x7.conv', 'ccd_44', 'median_1', -7, 1.0, 64, 63, 62, 43, 64, 59, 66, 47, 63, 48, 54, 21, 67, 45, 27, 45, 820, 934, 0, 184), (1.0, 2.0, 'mexhat_5.0_11x11.conv', 'ccd_44', 'median_1', -7, 1.0, 66, 63, 64, 47, 66, 62, 65, 48, 61, 49, 56, 26, 67, 59, 45, 45, 873, 4695, 7, 141), (3.0, 5.0, 'mexhat_2.5_7x7.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 64, 65, 49, 68, 64, 68, 50, 64, 49, 59, 30, 69, 55, 34, 47, 882, 1749, 1, 158), (1.0, 2.0, 'tophat_2.0_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 68, 63, 66, 50, 67, 63, 65, 49, 62, 48, 57, 26, 69, 57, 48, 45, 906, 14535, 23, 143), (2.0, 4.0, 'tophat_3.0_3x3.conv', 'ccd_44', 'median_1', -7, 1.0, 69, 63, 65, 48, 66, 64, 67, 50, 65, 50, 59, 30, 68, 57, 45, 46, 894, 4520, 6, 142)]\n",
      "123\n",
      "[0, 1, 14]\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 70704.0 failed 1 times, most recent failure: Lost task 0.0 in stage 70704.0 (TID 311470, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/rdd.py\", line 1354, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-77-526abf4ffd00>\", line 54, in <lambda>\nIndexError: tuple index out of range\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/rdd.py\", line 1354, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-77-526abf4ffd00>\", line 54, in <lambda>\nIndexError: tuple index out of range\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-665c00f5149e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mogim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/mj1e16/Simages/diff_{}_{}.fits'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mimName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/mj1e16/Simages/diff_{}_{}{}_alt.fits'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mbestSettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluateImageHillClimbVersionTwo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mogim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ccd_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'median_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmallName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newRun5_{}_{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muncacheTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starlist_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-526abf4ffd00>\u001b[0m in \u001b[0;36mevaluateImageHillClimbVersionTwo\u001b[0;34m(valList, simImage, OGImage, ccd, median, norm, minmag, smallName, starting, atList)\u001b[0m\n\u001b[1;32m     54\u001b[0m                                    totNum=int(x[23]),totGross=int(x[24]),OGtot=int(x[25]),OGtotGross=int(x[26]),score=int(x[27])))\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mschemaKepler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkepler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m#print('finalResults_{}_{}_{}'.format(ccd,median,minmag))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mschemaKepler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jdbc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jdbc:mysql://localhost/Kepler'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'com.mysql.jdbc.Driver'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdbtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'finalResultsHillClimb_{}_{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminmag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mj1e16'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'[sqlT1G3R]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/sql/context.pyc\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mPy4JJavaError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/sql/session.pyc\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/sql/session.pyc\u001b[0m in \u001b[0;36m_createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/sql/session.pyc\u001b[0m in \u001b[0;36m_inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructType\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             raise ValueError(\"The first row in RDD is empty, \"\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \"\"\"\n\u001b[0;32m-> 1378\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/context.pyc\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/py4j/protocol.pyc\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 70704.0 failed 1 times, most recent failure: Lost task 0.0 in stage 70704.0 (TID 311470, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/rdd.py\", line 1354, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-77-526abf4ffd00>\", line 54, in <lambda>\nIndexError: tuple index out of range\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 393, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/rdd.py\", line 1354, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-77-526abf4ffd00>\", line 54, in <lambda>\nIndexError: tuple index out of range\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:153)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "### Make function to replace starlist\n",
    "bestSettings = []\n",
    "for inc,c in enumerate(ccd):\n",
    "    for inmed,med in enumerate(median):\n",
    "        norm = norms[0][1]\n",
    "        #subprocess.call(['mkdir','/home/mj1e16/keplerPhotometry/provDump/{}/{}'.format(c,med)])\n",
    "        for mag in mags:\n",
    "            sqlContext.cacheTable('starlist_{}'.format(abs(mag)))\n",
    "            #subprocess.call(['mkdir','/data/mj1e16/provDump/{}/{}/{}'.format(c,med,mag)])\n",
    "            ogim = '/home/mj1e16/Simages/diff_{}_{}.fits'.format(c,med)\n",
    "            imName = '/home/mj1e16/Simages/diff_{}_{}{}_alt.fits'.format(c,med,mag)\n",
    "            bestSettings.append(evaluateImageHillClimbVersionTwo(valList,imName,ogim,'ccd_{}'.format(c),'median_{}'.format(med),norm,mag,smallName='newRun5_{}_{}_{}'.format(c,med,mag),starting=[4,6,12]))\n",
    "            sqlContext.uncacheTable('starlist_{}'.format(abs(mag)))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5, 19], [5, 4, 17], [0, 1, 14], [0, 1, 8], [0, 4, 19], [0, 1, 8], [2, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(bestSettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(bestSettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1.0, 1.0, 8.0, 3.0, 'ccd_44', 'median_1', -7, 1.0, 67, 62, 64, 48, 70, 67, 68, 51, 70, 67, 64, 30, 70, 67, 68, 48, 67, 62, 64, 48, 70, 67, 68, 51, 70, 67, 64, 30, 70, 67, 68, 48, 967, 15760]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1.0, 1.0, 8.0, 3.0, 'ccd_44', 'median_1', -7, 1.0, 67, 67, 62, 62, 64, 64, 48, 48, 70, 70, 67, 67, 68, 68, 51, 51, 70, 70, 67, 67, 64, 64, 30, 30, 70, 70, 67, 67, 68, 68, 48, 48, 967, 15760]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tup = [(1,2,3),(4,5,6)]\n",
    "rdd = sc.parallelize(tup)\n",
    "kepler = rdd.map(lambda x: Row(one=int(x[0]),two=int(x[1]),three=int(x[2])))\n",
    "schemaKepler = sqlContext.createDataFrame(kepler)\n",
    "schemaKepler.write.format('jdbc').options(url='jdbc:mysql://localhost/Kepler',driver='com.mysql.jdbc.Driver',dbtable='testTab',user='mj1e16',password='[sqlT1G3R]').mode('append').save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+\n",
      "|database| tableName|isTemporary|\n",
      "+--------+----------+-----------+\n",
      "|        |starlist_1|       true|\n",
      "|        |starlist_2|       true|\n",
      "|        |starlist_3|       true|\n",
      "|        |starlist_4|       true|\n",
      "|        |starlist_5|       true|\n",
      "|        |starlist_6|       true|\n",
      "|        |starlist_7|       true|\n",
      "+--------+----------+-----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "a = sqlContext.sql(\"show tables\").show()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    row = [('tabName',1,1),('tabName2',1,2)]\n",
    "    rdd = sc.parallelize(row)\n",
    "    kepler = rdd.map(lambda x: Row(tabName=x[0], xyRegion=int(x[1]),magRegion=int(x[2])))\n",
    "    schemaKepler = sqlContext.createDataFrame(kepler)\n",
    "    df = schemaKepler.toPandas()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testPartial(value):\n",
    "    return (value) #,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "p = ThreadPool(6)\n",
    "values = [0,1,2,3,4,5]\n",
    "answer = []\n",
    "for x in range(5):\n",
    "    answer.extend(p.map(testPartial,values))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findMagRange(catName):\n",
    "    assoc = Table.read(catName,format='ascii.sextractor')\n",
    "    df = assoc.to_pandas()\n",
    "    df2 = df[df['MAG_BEST'] != 99.0000]\n",
    "    #df3 = df[df['MAG_BEST'] == 99.0000]\n",
    "    maxVal = df2['MAG_BEST'].max()\n",
    "    minVal = df2['MAG_BEST'].min()\n",
    "#     df4 = df2.sort_values('MAG_BEST')\n",
    "#     return df4\n",
    "    print(minVal,maxVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findMagRange(catName):\n",
    "    assoc = Table.read(catName,format='ascii.sextractor')\n",
    "    df = assoc.to_pandas()\n",
    "    df2 = df[df['MAG_BEST'] != 99.0000]\n",
    "    #df3 = df[df['MAG_BEST'] == 99.0000]\n",
    "#     maxVal = df2['MAG_BEST'].max()\n",
    "#     minVal = df2['MAG_BEST'].min()\n",
    "    df4 = df2.sort_values('MAG_BEST')\n",
    "    return df4\n",
    "#     print(minVal,maxVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mj1e16/sextractor/sextractor-master/config/test0.cat\n",
      "/home/mj1e16/sextractor/sextractor-master/config/test1.cat\n",
      "/home/mj1e16/sextractor/sextractor-master/config/test2.cat\n",
      "/home/mj1e16/sextractor/sextractor-master/config/test3.cat\n",
      "/home/mj1e16/sextractor/sextractor-master/config/test4.cat\n",
      "/home/mj1e16/sextractor/sextractor-master/config/test5.cat\n"
     ]
    }
   ],
   "source": [
    "for x in range(6):\n",
    "    print('/home/mj1e16/sextractor/sextractor-master/config/test{}.cat'.format(x))\n",
    "    findMagRange('/home/mj1e16/sextractor/sextractor-master/config/test{}.cat'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 2\n",
    "df = findMagRange('/home/mj1e16/sextractor/sextractor-master/config/test{}.cat'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>MAG_BEST</th>\n",
       "      <th>X_IMAGE</th>\n",
       "      <th>Y_IMAGE</th>\n",
       "      <th>ELLIPTICITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>3026</td>\n",
       "      <td>13.0256</td>\n",
       "      <td>782.0090</td>\n",
       "      <td>185.0009</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>2870</td>\n",
       "      <td>13.0305</td>\n",
       "      <td>1052.8906</td>\n",
       "      <td>184.9989</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13573</th>\n",
       "      <td>13574</td>\n",
       "      <td>13.0327</td>\n",
       "      <td>1052.7808</td>\n",
       "      <td>946.0535</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>13345</td>\n",
       "      <td>13.0328</td>\n",
       "      <td>239.7816</td>\n",
       "      <td>946.0737</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>6970</td>\n",
       "      <td>13.0329</td>\n",
       "      <td>239.5148</td>\n",
       "      <td>437.8912</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11193</th>\n",
       "      <td>11194</td>\n",
       "      <td>13.0329</td>\n",
       "      <td>239.6400</td>\n",
       "      <td>691.9606</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13666</th>\n",
       "      <td>13667</td>\n",
       "      <td>13.0333</td>\n",
       "      <td>781.5560</td>\n",
       "      <td>946.0166</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>6969</td>\n",
       "      <td>13.0335</td>\n",
       "      <td>781.4474</td>\n",
       "      <td>438.1546</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>7011</td>\n",
       "      <td>13.0338</td>\n",
       "      <td>510.7693</td>\n",
       "      <td>437.9970</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>2860</td>\n",
       "      <td>13.0340</td>\n",
       "      <td>239.8327</td>\n",
       "      <td>185.1199</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>11099</td>\n",
       "      <td>13.0341</td>\n",
       "      <td>510.8086</td>\n",
       "      <td>692.0192</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11096</th>\n",
       "      <td>11097</td>\n",
       "      <td>13.0343</td>\n",
       "      <td>781.8524</td>\n",
       "      <td>692.0643</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16177</th>\n",
       "      <td>16178</td>\n",
       "      <td>13.0348</td>\n",
       "      <td>510.7735</td>\n",
       "      <td>945.9639</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>2861</td>\n",
       "      <td>13.0349</td>\n",
       "      <td>510.7512</td>\n",
       "      <td>185.0112</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>6957</td>\n",
       "      <td>13.0379</td>\n",
       "      <td>1052.8188</td>\n",
       "      <td>438.0684</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11207</th>\n",
       "      <td>11208</td>\n",
       "      <td>13.0408</td>\n",
       "      <td>1052.9272</td>\n",
       "      <td>692.0045</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>6474</td>\n",
       "      <td>13.3594</td>\n",
       "      <td>316.6791</td>\n",
       "      <td>394.9765</td>\n",
       "      <td>0.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2448</td>\n",
       "      <td>13.3612</td>\n",
       "      <td>587.9571</td>\n",
       "      <td>142.0876</td>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>6272</td>\n",
       "      <td>13.3652</td>\n",
       "      <td>45.3941</td>\n",
       "      <td>395.1005</td>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>10805</td>\n",
       "      <td>13.3658</td>\n",
       "      <td>316.7459</td>\n",
       "      <td>649.0609</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14055</th>\n",
       "      <td>14056</td>\n",
       "      <td>13.3664</td>\n",
       "      <td>45.7228</td>\n",
       "      <td>903.1291</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>6235</td>\n",
       "      <td>13.3668</td>\n",
       "      <td>858.6958</td>\n",
       "      <td>395.0254</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2154</td>\n",
       "      <td>13.3673</td>\n",
       "      <td>45.7760</td>\n",
       "      <td>142.1422</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10549</th>\n",
       "      <td>10550</td>\n",
       "      <td>13.3678</td>\n",
       "      <td>587.7603</td>\n",
       "      <td>649.0553</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>2337</td>\n",
       "      <td>13.3680</td>\n",
       "      <td>316.7120</td>\n",
       "      <td>142.0061</td>\n",
       "      <td>0.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14024</th>\n",
       "      <td>14025</td>\n",
       "      <td>13.3681</td>\n",
       "      <td>316.6086</td>\n",
       "      <td>903.0159</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>2184</td>\n",
       "      <td>13.3682</td>\n",
       "      <td>858.8000</td>\n",
       "      <td>142.0176</td>\n",
       "      <td>0.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>13749</td>\n",
       "      <td>13.3688</td>\n",
       "      <td>858.7222</td>\n",
       "      <td>903.0233</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>10496</td>\n",
       "      <td>13.3709</td>\n",
       "      <td>45.5791</td>\n",
       "      <td>649.1753</td>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729</th>\n",
       "      <td>13730</td>\n",
       "      <td>13.3756</td>\n",
       "      <td>587.9306</td>\n",
       "      <td>903.5709</td>\n",
       "      <td>0.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14676</th>\n",
       "      <td>14677</td>\n",
       "      <td>24.0188</td>\n",
       "      <td>836.7562</td>\n",
       "      <td>864.1889</td>\n",
       "      <td>0.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8099</th>\n",
       "      <td>8100</td>\n",
       "      <td>24.0959</td>\n",
       "      <td>294.3757</td>\n",
       "      <td>513.5812</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>2973</td>\n",
       "      <td>24.0975</td>\n",
       "      <td>341.0770</td>\n",
       "      <td>205.6364</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>7852</td>\n",
       "      <td>24.2013</td>\n",
       "      <td>546.6121</td>\n",
       "      <td>502.1548</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>13893</td>\n",
       "      <td>24.2430</td>\n",
       "      <td>410.0000</td>\n",
       "      <td>910.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>680</td>\n",
       "      <td>24.2489</td>\n",
       "      <td>983.0000</td>\n",
       "      <td>65.5379</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15724</th>\n",
       "      <td>15725</td>\n",
       "      <td>24.2829</td>\n",
       "      <td>819.7879</td>\n",
       "      <td>992.2663</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>5875</td>\n",
       "      <td>24.3973</td>\n",
       "      <td>1068.4451</td>\n",
       "      <td>383.4673</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11652</th>\n",
       "      <td>11653</td>\n",
       "      <td>24.4965</td>\n",
       "      <td>839.4059</td>\n",
       "      <td>733.6541</td>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12929</th>\n",
       "      <td>12930</td>\n",
       "      <td>24.5132</td>\n",
       "      <td>870.3439</td>\n",
       "      <td>819.2492</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5581</th>\n",
       "      <td>5582</td>\n",
       "      <td>24.5239</td>\n",
       "      <td>344.9995</td>\n",
       "      <td>365.5396</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>5161</td>\n",
       "      <td>24.5697</td>\n",
       "      <td>1092.0000</td>\n",
       "      <td>335.9767</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>8011</td>\n",
       "      <td>24.6286</td>\n",
       "      <td>779.4526</td>\n",
       "      <td>508.2274</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11304</th>\n",
       "      <td>11305</td>\n",
       "      <td>24.8699</td>\n",
       "      <td>780.3720</td>\n",
       "      <td>712.2123</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>3241</td>\n",
       "      <td>24.8770</td>\n",
       "      <td>460.4622</td>\n",
       "      <td>221.5273</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6138</th>\n",
       "      <td>6139</td>\n",
       "      <td>24.9127</td>\n",
       "      <td>642.1222</td>\n",
       "      <td>398.8473</td>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7243</th>\n",
       "      <td>7244</td>\n",
       "      <td>24.9638</td>\n",
       "      <td>940.1658</td>\n",
       "      <td>463.4750</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15408</th>\n",
       "      <td>15409</td>\n",
       "      <td>24.9706</td>\n",
       "      <td>1086.9135</td>\n",
       "      <td>1005.1381</td>\n",
       "      <td>0.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>9374</td>\n",
       "      <td>25.0055</td>\n",
       "      <td>975.0000</td>\n",
       "      <td>600.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9580</th>\n",
       "      <td>9581</td>\n",
       "      <td>25.3569</td>\n",
       "      <td>1087.3734</td>\n",
       "      <td>607.9286</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>5376</td>\n",
       "      <td>25.3569</td>\n",
       "      <td>585.0000</td>\n",
       "      <td>351.5077</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11716</th>\n",
       "      <td>11717</td>\n",
       "      <td>25.4487</td>\n",
       "      <td>1094.4670</td>\n",
       "      <td>740.9803</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>3742</td>\n",
       "      <td>25.4786</td>\n",
       "      <td>1006.2031</td>\n",
       "      <td>251.2441</td>\n",
       "      <td>0.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>5277</td>\n",
       "      <td>25.6058</td>\n",
       "      <td>578.1317</td>\n",
       "      <td>345.6117</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>25.8393</td>\n",
       "      <td>264.6360</td>\n",
       "      <td>76.7686</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>13100</td>\n",
       "      <td>25.9330</td>\n",
       "      <td>996.7485</td>\n",
       "      <td>828.3057</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>3772</td>\n",
       "      <td>26.2903</td>\n",
       "      <td>351.2291</td>\n",
       "      <td>255.6809</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>26.3007</td>\n",
       "      <td>154.0000</td>\n",
       "      <td>48.4807</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>3145</td>\n",
       "      <td>27.0502</td>\n",
       "      <td>556.0000</td>\n",
       "      <td>218.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>2232</td>\n",
       "      <td>27.8809</td>\n",
       "      <td>379.3352</td>\n",
       "      <td>157.8504</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15709 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NUMBER  MAG_BEST    X_IMAGE    Y_IMAGE  ELLIPTICITY\n",
       "3025     3026   13.0256   782.0090   185.0009        0.352\n",
       "2869     2870   13.0305  1052.8906   184.9989        0.036\n",
       "13573   13574   13.0327  1052.7808   946.0535        0.125\n",
       "13344   13345   13.0328   239.7816   946.0737        0.031\n",
       "6969     6970   13.0329   239.5148   437.8912        0.103\n",
       "11193   11194   13.0329   239.6400   691.9606        0.054\n",
       "13666   13667   13.0333   781.5560   946.0166        0.260\n",
       "6968     6969   13.0335   781.4474   438.1546        0.157\n",
       "7010     7011   13.0338   510.7693   437.9970        0.031\n",
       "2859     2860   13.0340   239.8327   185.1199        0.095\n",
       "11098   11099   13.0341   510.8086   692.0192        0.053\n",
       "11096   11097   13.0343   781.8524   692.0643        0.048\n",
       "16177   16178   13.0348   510.7735   945.9639        0.073\n",
       "2860     2861   13.0349   510.7512   185.0112        0.098\n",
       "6956     6957   13.0379  1052.8188   438.0684        0.059\n",
       "11207   11208   13.0408  1052.9272   692.0045        0.114\n",
       "6473     6474   13.3594   316.6791   394.9765        0.363\n",
       "2447     2448   13.3612   587.9571   142.0876        0.295\n",
       "6271     6272   13.3652    45.3941   395.1005        0.249\n",
       "10804   10805   13.3658   316.7459   649.0609        0.361\n",
       "14055   14056   13.3664    45.7228   903.1291        0.350\n",
       "6234     6235   13.3668   858.6958   395.0254        0.383\n",
       "2153     2154   13.3673    45.7760   142.1422        0.315\n",
       "10549   10550   13.3678   587.7603   649.0553        0.326\n",
       "2336     2337   13.3680   316.7120   142.0061        0.355\n",
       "14024   14025   13.3681   316.6086   903.0159        0.324\n",
       "2183     2184   13.3682   858.8000   142.0176        0.334\n",
       "13748   13749   13.3688   858.7222   903.0233        0.360\n",
       "10495   10496   13.3709    45.5791   649.1753        0.295\n",
       "13729   13730   13.3756   587.9306   903.5709        0.303\n",
       "...       ...       ...        ...        ...          ...\n",
       "14676   14677   24.0188   836.7562   864.1889        0.585\n",
       "8099     8100   24.0959   294.3757   513.5812        0.420\n",
       "2972     2973   24.0975   341.0770   205.6364        0.658\n",
       "7851     7852   24.2013   546.6121   502.1548        0.320\n",
       "13892   13893   24.2430   410.0000   910.0000        0.000\n",
       "679       680   24.2489   983.0000    65.5379        0.499\n",
       "15724   15725   24.2829   819.7879   992.2663        0.283\n",
       "5874     5875   24.3973  1068.4451   383.4673        0.125\n",
       "11652   11653   24.4965   839.4059   733.6541        0.430\n",
       "12929   12930   24.5132   870.3439   819.2492        0.365\n",
       "5581     5582   24.5239   344.9995   365.5396        0.482\n",
       "5160     5161   24.5697  1092.0000   335.9767        0.609\n",
       "8010     8011   24.6286   779.4526   508.2274        0.381\n",
       "11304   11305   24.8699   780.3720   712.2123        0.400\n",
       "3240     3241   24.8770   460.4622   221.5273        0.100\n",
       "6138     6139   24.9127   642.1222   398.8473        0.376\n",
       "7243     7244   24.9638   940.1658   463.4750        0.323\n",
       "15408   15409   24.9706  1086.9135  1005.1381        0.478\n",
       "9373     9374   25.0055   975.0000   600.0000        0.000\n",
       "9580     9581   25.3569  1087.3734   607.9286        0.378\n",
       "5375     5376   25.3569   585.0000   351.5077        0.500\n",
       "11716   11717   25.4487  1094.4670   740.9803        0.313\n",
       "3741     3742   25.4786  1006.2031   251.2441        0.585\n",
       "5276     5277   25.6058   578.1317   345.6117        0.386\n",
       "886       887   25.8393   264.6360    76.7686        0.460\n",
       "13099   13100   25.9330   996.7485   828.3057        0.282\n",
       "3771     3772   26.2903   351.2291   255.6809        0.313\n",
       "398       399   26.3007   154.0000    48.4807        0.500\n",
       "3144     3145   27.0502   556.0000   218.0000        0.000\n",
       "2231     2232   27.8809   379.3352   157.8504        0.313\n",
       "\n",
       "[15709 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "magRange = np.linspace(15,30,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,\n",
       "        26.,  27.,  28.,  29.,  30.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00117707252502\n"
     ]
    }
   ],
   "source": [
    "catName = 'test0.cat'\n",
    "\n",
    "assoc = Table.read(catName,format='ascii.sextractor')\n",
    "t0 = time.time()\n",
    "df = assoc.to_pandas()\n",
    "#df2 = df[df['MAG_BEST'] != 99.0000]\n",
    "print(time.time()-t0) #, totGross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73592019081\n",
      "(0.06544804573059082, 16094)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "df_spark = sqlContext.createDataFrame(df)\n",
    "print(time.time()-t0) #, totGross)\n",
    "\n",
    "t0 = time.time()\n",
    "totGross = df_spark.count()\n",
    "print(time.time()-t0, totGross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#   1 NUMBER                 Running object number                                     \r\n",
      "#   2 MAG_BEST               Best of MAG_AUTO and MAG_ISOCOR                            [mag]\r\n",
      "#   3 X_IMAGE                Object position along x                                    [pixel]\r\n",
      "#   4 Y_IMAGE                Object position along y                                    [pixel]\r\n",
      "#   5 ELLIPTICITY            1 - B_IMAGE/A_IMAGE                                       \r\n",
      "         1  20.7173    744.5268     19.6496    0.438\r\n",
      "         2  99.0000   1000.7009     19.5017    0.285\r\n",
      "         3  99.0000    133.3164     20.2157    0.325\r\n",
      "         4  21.8619    138.0000     20.4564    0.499\r\n",
      "         5  21.5303    779.9139     23.0000    0.633\r\n"
     ]
    }
   ],
   "source": [
    "!head test0.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [3]]\n",
      "[[1], [3]]\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "vals = [[x],[1],[2]]\n",
    "val = [[x],[3]]\n",
    "print(val)\n",
    "x = 1\n",
    "val = [[x],[3]]\n",
    "print(val)\n",
    "vals.append(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "smallName = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_0_0_0_0\n",
      "[[1.0, 1.0, 8.0, 1]]\n",
      "test_0_0_1_0\n",
      "[[1.0, 1.0, 16.0, 1]]\n",
      "test_0_0_2_0\n",
      "[[1.0, 1.0, 24.0, 1]]\n",
      "test_0_1_0_0\n",
      "[[1.0, 2.0, 8.0, 1]]\n",
      "test_0_1_1_0\n",
      "[[1.0, 2.0, 16.0, 1]]\n",
      "test_0_1_2_0\n",
      "[[1.0, 2.0, 24.0, 1]]\n",
      "test_0_2_0_0\n",
      "[[1.0, 3.0, 8.0, 1]]\n",
      "test_0_2_1_0\n",
      "[[1.0, 3.0, 16.0, 1]]\n",
      "test_0_2_2_0\n",
      "[[1.0, 3.0, 24.0, 1]]\n",
      "test_1_0_0_0\n",
      "[[2.0, 1.0, 8.0, 1]]\n",
      "test_1_0_1_0\n",
      "[[2.0, 1.0, 16.0, 1]]\n",
      "test_1_0_2_0\n",
      "[[2.0, 1.0, 24.0, 1]]\n",
      "test_1_1_0_0\n",
      "[[2.0, 2.0, 8.0, 1]]\n",
      "test_1_1_1_0\n",
      "[[2.0, 2.0, 16.0, 1]]\n",
      "test_1_1_2_0\n",
      "[[2.0, 2.0, 24.0, 1]]\n",
      "test_1_2_0_0\n",
      "[[2.0, 3.0, 8.0, 1]]\n",
      "test_1_2_1_0\n",
      "[[2.0, 3.0, 16.0, 1]]\n",
      "test_1_2_2_0\n",
      "[[2.0, 3.0, 24.0, 1]]\n",
      "test_2_0_0_0\n",
      "[[3.0, 1.0, 8.0, 1]]\n",
      "test_2_0_1_0\n",
      "[[3.0, 1.0, 16.0, 1]]\n",
      "test_2_0_2_0\n",
      "[[3.0, 1.0, 24.0, 1]]\n",
      "test_2_1_0_0\n",
      "[[3.0, 2.0, 8.0, 1]]\n",
      "test_2_1_1_0\n",
      "[[3.0, 2.0, 16.0, 1]]\n",
      "test_2_1_2_0\n",
      "[[3.0, 2.0, 24.0, 1]]\n",
      "test_2_2_0_0\n",
      "[[3.0, 3.0, 8.0, 1]]\n",
      "test_2_2_1_0\n",
      "[[3.0, 3.0, 16.0, 1]]\n",
      "test_2_2_2_0\n",
      "[[3.0, 3.0, 24.0, 1]]\n",
      "test_0_0_0_0\n",
      "[[1.0, 1.0, 8.0, 3]]\n",
      "test_0_0_1_0\n",
      "[[1.0, 1.0, 16.0, 3]]\n",
      "test_0_0_2_0\n",
      "[[1.0, 1.0, 24.0, 3]]\n",
      "test_0_1_0_0\n",
      "[[1.0, 2.0, 8.0, 3]]\n",
      "test_0_1_1_0\n",
      "[[1.0, 2.0, 16.0, 3]]\n",
      "test_0_1_2_0\n",
      "[[1.0, 2.0, 24.0, 3]]\n",
      "test_0_2_0_0\n",
      "[[1.0, 3.0, 8.0, 3]]\n",
      "test_0_2_1_0\n",
      "[[1.0, 3.0, 16.0, 3]]\n",
      "test_0_2_2_0\n",
      "[[1.0, 3.0, 24.0, 3]]\n",
      "test_1_0_0_0\n",
      "[[2.0, 1.0, 8.0, 3]]\n",
      "test_1_0_1_0\n",
      "[[2.0, 1.0, 16.0, 3]]\n",
      "test_1_0_2_0\n",
      "[[2.0, 1.0, 24.0, 3]]\n",
      "test_1_1_0_0\n",
      "[[2.0, 2.0, 8.0, 3]]\n",
      "test_1_1_1_0\n",
      "[[2.0, 2.0, 16.0, 3]]\n",
      "test_1_1_2_0\n",
      "[[2.0, 2.0, 24.0, 3]]\n",
      "test_1_2_0_0\n",
      "[[2.0, 3.0, 8.0, 3]]\n",
      "test_1_2_1_0\n",
      "[[2.0, 3.0, 16.0, 3]]\n",
      "test_1_2_2_0\n",
      "[[2.0, 3.0, 24.0, 3]]\n",
      "test_2_0_0_0\n",
      "[[3.0, 1.0, 8.0, 3]]\n",
      "test_2_0_1_0\n",
      "[[3.0, 1.0, 16.0, 3]]\n",
      "test_2_0_2_0\n",
      "[[3.0, 1.0, 24.0, 3]]\n",
      "test_2_1_0_0\n",
      "[[3.0, 2.0, 8.0, 3]]\n",
      "test_2_1_1_0\n",
      "[[3.0, 2.0, 16.0, 3]]\n",
      "test_2_1_2_0\n",
      "[[3.0, 2.0, 24.0, 3]]\n",
      "test_2_2_0_0\n",
      "[[3.0, 3.0, 8.0, 3]]\n",
      "test_2_2_1_0\n",
      "[[3.0, 3.0, 16.0, 3]]\n",
      "test_2_2_2_0\n",
      "[[3.0, 3.0, 24.0, 3]]\n",
      "test_0_0_0_0\n",
      "[[1.0, 1.0, 8.0, 5]]\n",
      "test_0_0_1_0\n",
      "[[1.0, 1.0, 16.0, 5]]\n",
      "test_0_0_2_0\n",
      "[[1.0, 1.0, 24.0, 5]]\n",
      "test_0_1_0_0\n",
      "[[1.0, 2.0, 8.0, 5]]\n",
      "test_0_1_1_0\n",
      "[[1.0, 2.0, 16.0, 5]]\n",
      "test_0_1_2_0\n",
      "[[1.0, 2.0, 24.0, 5]]\n",
      "test_0_2_0_0\n",
      "[[1.0, 3.0, 8.0, 5]]\n",
      "test_0_2_1_0\n",
      "[[1.0, 3.0, 16.0, 5]]\n",
      "test_0_2_2_0\n",
      "[[1.0, 3.0, 24.0, 5]]\n",
      "test_1_0_0_0\n",
      "[[2.0, 1.0, 8.0, 5]]\n",
      "test_1_0_1_0\n",
      "[[2.0, 1.0, 16.0, 5]]\n",
      "test_1_0_2_0\n",
      "[[2.0, 1.0, 24.0, 5]]\n",
      "test_1_1_0_0\n",
      "[[2.0, 2.0, 8.0, 5]]\n",
      "test_1_1_1_0\n",
      "[[2.0, 2.0, 16.0, 5]]\n",
      "test_1_1_2_0\n",
      "[[2.0, 2.0, 24.0, 5]]\n",
      "test_1_2_0_0\n",
      "[[2.0, 3.0, 8.0, 5]]\n",
      "test_1_2_1_0\n",
      "[[2.0, 3.0, 16.0, 5]]\n",
      "test_1_2_2_0\n",
      "[[2.0, 3.0, 24.0, 5]]\n",
      "test_2_0_0_0\n",
      "[[3.0, 1.0, 8.0, 5]]\n",
      "test_2_0_1_0\n",
      "[[3.0, 1.0, 16.0, 5]]\n",
      "test_2_0_2_0\n",
      "[[3.0, 1.0, 24.0, 5]]\n",
      "test_2_1_0_0\n",
      "[[3.0, 2.0, 8.0, 5]]\n",
      "test_2_1_1_0\n",
      "[[3.0, 2.0, 16.0, 5]]\n",
      "test_2_1_2_0\n",
      "[[3.0, 2.0, 24.0, 5]]\n",
      "test_2_2_0_0\n",
      "[[3.0, 3.0, 8.0, 5]]\n",
      "test_2_2_1_0\n",
      "[[3.0, 3.0, 16.0, 5]]\n",
      "test_2_2_2_0\n",
      "[[3.0, 3.0, 24.0, 5]]\n",
      "test_0_0_0_0\n",
      "[[1.0, 1.0, 8.0, 7]]\n",
      "test_0_0_1_0\n",
      "[[1.0, 1.0, 16.0, 7]]\n",
      "test_0_0_2_0\n",
      "[[1.0, 1.0, 24.0, 7]]\n",
      "test_0_1_0_0\n",
      "[[1.0, 2.0, 8.0, 7]]\n",
      "test_0_1_1_0\n",
      "[[1.0, 2.0, 16.0, 7]]\n",
      "test_0_1_2_0\n",
      "[[1.0, 2.0, 24.0, 7]]\n",
      "test_0_2_0_0\n",
      "[[1.0, 3.0, 8.0, 7]]\n",
      "test_0_2_1_0\n",
      "[[1.0, 3.0, 16.0, 7]]\n",
      "test_0_2_2_0\n",
      "[[1.0, 3.0, 24.0, 7]]\n",
      "test_1_0_0_0\n",
      "[[2.0, 1.0, 8.0, 7]]\n",
      "test_1_0_1_0\n",
      "[[2.0, 1.0, 16.0, 7]]\n",
      "test_1_0_2_0\n",
      "[[2.0, 1.0, 24.0, 7]]\n",
      "test_1_1_0_0\n",
      "[[2.0, 2.0, 8.0, 7]]\n",
      "test_1_1_1_0\n",
      "[[2.0, 2.0, 16.0, 7]]\n",
      "test_1_1_2_0\n",
      "[[2.0, 2.0, 24.0, 7]]\n",
      "test_1_2_0_0\n",
      "[[2.0, 3.0, 8.0, 7]]\n",
      "test_1_2_1_0\n",
      "[[2.0, 3.0, 16.0, 7]]\n",
      "test_1_2_2_0\n",
      "[[2.0, 3.0, 24.0, 7]]\n",
      "test_2_0_0_0\n",
      "[[3.0, 1.0, 8.0, 7]]\n",
      "test_2_0_1_0\n",
      "[[3.0, 1.0, 16.0, 7]]\n",
      "test_2_0_2_0\n",
      "[[3.0, 1.0, 24.0, 7]]\n",
      "test_2_1_0_0\n",
      "[[3.0, 2.0, 8.0, 7]]\n",
      "test_2_1_1_0\n",
      "[[3.0, 2.0, 16.0, 7]]\n",
      "test_2_1_2_0\n",
      "[[3.0, 2.0, 24.0, 7]]\n",
      "test_2_2_0_0\n",
      "[[3.0, 3.0, 8.0, 7]]\n",
      "test_2_2_1_0\n",
      "[[3.0, 3.0, 16.0, 7]]\n",
      "test_2_2_2_0\n",
      "[[3.0, 3.0, 24.0, 7]]\n",
      "test_0_0_0_0\n",
      "[[1.0, 1.0, 8.0, 9]]\n",
      "test_0_0_1_0\n",
      "[[1.0, 1.0, 16.0, 9]]\n",
      "test_0_0_2_0\n",
      "[[1.0, 1.0, 24.0, 9]]\n",
      "test_0_1_0_0\n",
      "[[1.0, 2.0, 8.0, 9]]\n",
      "test_0_1_1_0\n",
      "[[1.0, 2.0, 16.0, 9]]\n",
      "test_0_1_2_0\n",
      "[[1.0, 2.0, 24.0, 9]]\n",
      "test_0_2_0_0\n",
      "[[1.0, 3.0, 8.0, 9]]\n",
      "test_0_2_1_0\n",
      "[[1.0, 3.0, 16.0, 9]]\n",
      "test_0_2_2_0\n",
      "[[1.0, 3.0, 24.0, 9]]\n",
      "test_1_0_0_0\n",
      "[[2.0, 1.0, 8.0, 9]]\n",
      "test_1_0_1_0\n",
      "[[2.0, 1.0, 16.0, 9]]\n",
      "test_1_0_2_0\n",
      "[[2.0, 1.0, 24.0, 9]]\n",
      "test_1_1_0_0\n",
      "[[2.0, 2.0, 8.0, 9]]\n",
      "test_1_1_1_0\n",
      "[[2.0, 2.0, 16.0, 9]]\n",
      "test_1_1_2_0\n",
      "[[2.0, 2.0, 24.0, 9]]\n",
      "test_1_2_0_0\n",
      "[[2.0, 3.0, 8.0, 9]]\n",
      "test_1_2_1_0\n",
      "[[2.0, 3.0, 16.0, 9]]\n",
      "test_1_2_2_0\n",
      "[[2.0, 3.0, 24.0, 9]]\n",
      "test_2_0_0_0\n",
      "[[3.0, 1.0, 8.0, 9]]\n",
      "test_2_0_1_0\n",
      "[[3.0, 1.0, 16.0, 9]]\n",
      "test_2_0_2_0\n",
      "[[3.0, 1.0, 24.0, 9]]\n",
      "test_2_1_0_0\n",
      "[[3.0, 2.0, 8.0, 9]]\n",
      "test_2_1_1_0\n",
      "[[3.0, 2.0, 16.0, 9]]\n",
      "test_2_1_2_0\n",
      "[[3.0, 2.0, 24.0, 9]]\n",
      "test_2_2_0_0\n",
      "[[3.0, 3.0, 8.0, 9]]\n",
      "test_2_2_1_0\n",
      "[[3.0, 3.0, 16.0, 9]]\n",
      "test_2_2_2_0\n",
      "[[3.0, 3.0, 24.0, 9]]\n",
      "test_0_0_0_0\n",
      "[[1.0, 1.0, 8.0, 11]]\n",
      "test_0_0_1_0\n",
      "[[1.0, 1.0, 16.0, 11]]\n",
      "test_0_0_2_0\n",
      "[[1.0, 1.0, 24.0, 11]]\n",
      "test_0_1_0_0\n",
      "[[1.0, 2.0, 8.0, 11]]\n",
      "test_0_1_1_0\n",
      "[[1.0, 2.0, 16.0, 11]]\n",
      "test_0_1_2_0\n",
      "[[1.0, 2.0, 24.0, 11]]\n",
      "test_0_2_0_0\n",
      "[[1.0, 3.0, 8.0, 11]]\n",
      "test_0_2_1_0\n",
      "[[1.0, 3.0, 16.0, 11]]\n",
      "test_0_2_2_0\n",
      "[[1.0, 3.0, 24.0, 11]]\n",
      "test_1_0_0_0\n",
      "[[2.0, 1.0, 8.0, 11]]\n",
      "test_1_0_1_0\n",
      "[[2.0, 1.0, 16.0, 11]]\n",
      "test_1_0_2_0\n",
      "[[2.0, 1.0, 24.0, 11]]\n",
      "test_1_1_0_0\n",
      "[[2.0, 2.0, 8.0, 11]]\n",
      "test_1_1_1_0\n",
      "[[2.0, 2.0, 16.0, 11]]\n",
      "test_1_1_2_0\n",
      "[[2.0, 2.0, 24.0, 11]]\n",
      "test_1_2_0_0\n",
      "[[2.0, 3.0, 8.0, 11]]\n",
      "test_1_2_1_0\n",
      "[[2.0, 3.0, 16.0, 11]]\n",
      "test_1_2_2_0\n",
      "[[2.0, 3.0, 24.0, 11]]\n",
      "test_2_0_0_0\n",
      "[[3.0, 1.0, 8.0, 11]]\n",
      "test_2_0_1_0\n",
      "[[3.0, 1.0, 16.0, 11]]\n",
      "test_2_0_2_0\n",
      "[[3.0, 1.0, 24.0, 11]]\n",
      "test_2_1_0_0\n",
      "[[3.0, 2.0, 8.0, 11]]\n",
      "test_2_1_1_0\n",
      "[[3.0, 2.0, 16.0, 11]]\n",
      "test_2_1_2_0\n",
      "[[3.0, 2.0, 24.0, 11]]\n",
      "test_2_2_0_0\n",
      "[[3.0, 3.0, 8.0, 11]]\n",
      "test_2_2_1_0\n",
      "[[3.0, 3.0, 16.0, 11]]\n",
      "test_2_2_2_0\n",
      "[[3.0, 3.0, 24.0, 11]]\n"
     ]
    }
   ],
   "source": [
    "valListminus1 = [1,3,5,7,9,11]\n",
    "for vals in (valListminus1):\n",
    "    valList = [np.linspace(1,10,10),np.linspace(1,9,9),np.linspace(8,128,16),[vals]]\n",
    "\n",
    "    finalTableTuples = []\n",
    "    #p = ThreadPool(1)\n",
    "    #t0 = time.time()\n",
    "    for x0 in range(3): #len(valList[0])):\n",
    "        for x1 in range(3): #len(valList[1])):\n",
    "                for x2 in range(3): #len(valList[2])):\n",
    "                    name = smallName+'_'+str(x0)+'_'+str(x1)+'_'+str(x2)+'_'\n",
    "                    fullname = [name]*len(valList[3])\n",
    "                    fullValList = []\n",
    "                    for x3 in range(len(valList[3])):\n",
    "                        fullname[x3] += str(x3)\n",
    "                        print(fullname[x3])\n",
    "                        fullValList.append([valList[0][x0],valList[1][x1],valList[2][x2],valList[3][x3]])\n",
    "\n",
    "                        #alltogethernow(fullValList[x4],fullname,imageName,provDir)\n",
    "                    print(fullValList)\n",
    "#                     try:\n",
    "#                         finalTableTuples.extend(p.map(partial(alltogethernow,tableName=fullname,IMAGE=simImage,provDir=provDir),fullValList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7., -6., -5., -4., -3., -2., -1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(-7,-1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
