{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import astroprov\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "\n",
    "import collections\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from astropy.io import ascii\n",
    "#from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import mysql.connector\n",
    "from pandas import DataFrame\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from mysql.connector import pooling\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /home/mj1e16/miniconda2/lib/python2.7/site-packages/pyspark/mysql-connector-java_8.0.16-1ubuntu16.04_all/usr/share/java/mysql-connector-java-8.0.16.jar  pyspark-shell'\n",
    "config = SparkConf().setAll([('spark.executor.cores', '6'),('spark.cores.max', '6'),('spark.driver.memory','1g'),('spark.executor.memory', '500m')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6155723d125c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'App'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataframe_mysql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jdbc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jdbc:mysql://localhost/Kepler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"driver\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"com.mysql.jdbc.Driver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dbtable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"starlist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mj1e16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"password\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"[sqlT1G3R]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataframe_mysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregisterTempTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starlist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/context.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/context.pyc\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/java_gateway.pyc\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mJVM\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_launch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mj1e16/miniconda2/envs/astroconda/lib/python2.7/site-packages/pyspark/java_gateway.pyc\u001b[0m in \u001b[0;36m_launch_gateway\u001b[0;34m(conf, insecure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName='App',conf=config)\n",
    "sqlContext = SQLContext(sc)\n",
    "dataframe_mysql = sqlContext.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://localhost/Kepler\").option(\"driver\", \"com.mysql.jdbc.Driver\").option(\"dbtable\", \"starlist\").option(\"user\", \"mj1e16\").option(\"password\", \"[sqlT1G3R]\").load()\n",
    "dataframe_mysql.registerTempTable('starlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def innerJoin(tableName,provDir,diffSize=1):\n",
    "    temptableName = tableName[0:5]+tableName[-1]\n",
    "    df = sqlContext.sql(\"SELECT NUMBER, EXT_NUMBER, FLUX_ISO, FLUXERR_ISO, BACKGROUND, THRESHOLD, FLUX_MAX, XPEAK_IMAGE, YPEAK_IMAGE,  X_IMAGE, Y_IMAGE, FWHM_IMAGE, ELLIPTICITY FROM {} INNER JOIN starlist ON {}.X_IMAGE BETWEEN starlist.X_POS_MIN AND starlist.X_POS_MAX AND {}.Y_IMAGE BETWEEN starlist.Y_POS_MIN AND starlist.Y_POS_MAX\".format(temptableName,temptableName,temptableName))\n",
    "    #df.write.format('jdbc').options(url='jdbc:mysql://localhost/Kepler',driver='com.mysql.jdbc.Driver',dbtable='result_{}'.format(tableName),user='mj1e16',password='[sqlT1G3R]').mode('append').save()\n",
    "    df = sqlContext.sql(\"SELECT NUMBER, EXT_NUMBER, FLUX_ISO, FLUXERR_ISO, BACKGROUND, THRESHOLD, FLUX_MAX, XPEAK_IMAGE, YPEAK_IMAGE,  X_IMAGE, Y_IMAGE, FWHM_IMAGE, ELLIPTICITY FROM {} INNER JOIN starlist ON {}.X_IMAGE BETWEEN {} AND {} AND {}.Y_IMAGE BETWEEN {} AND {}\".format(temptableName,temptableName,temptableName))\n",
    "\n",
    "    \n",
    "    sqlContext.dropTempTable(temptableName)\n",
    "    astroprov.provcall([tableName,'starlist'],['result_{}'.format(tableName)],\"innerJoin_Python2Python_SQ_tmpl.provn\",\"innerJoin\",provDir)\n",
    "\n",
    "\n",
    "def makeConfig(valList,provDir,tableName='table',defaultDir='/home/mj1e16/sextractor/sextractor-master/config/',attributeList=['DETECT_THRESH','DETECT_MINAREA','BACK_SIZE','BACK_FILTERSIZE']):\n",
    "    \n",
    "    #workAroundList = [16,32,64,128,256,512]\n",
    "    workAroundList = [1,3,5,7,9,11]\n",
    "    ident = workAroundList.index(valList[-1])\n",
    "    tableName = tableName[ident] # could just return a letter?\n",
    "    with open(defaultDir+'/default.sex','r') as f:\n",
    "        data  = f.read()\n",
    "    \n",
    "    catLocFinder = 'CATALOG_NAME'\n",
    "    catname = 'test'+str(ident)+'.cat'\n",
    "    nameLoc = data.find(catLocFinder) + len(catLocFinder)\n",
    "    endLoc = data[nameLoc:].find('#') + nameLoc\n",
    "    newData = data[:nameLoc] + ' '+catname+' ' + data[endLoc:]\n",
    "    data = newData \n",
    "        \n",
    "    for x in range(len(valList)):\n",
    "        nameLoc = data.find(attributeList[x]) + len(attributeList[x])\n",
    "        endLoc = data[nameLoc:].find('#') + nameLoc\n",
    "        newData = data[:nameLoc] + ' '+str(valList[x])+' ' + data[endLoc:]\n",
    "        data = newData    \n",
    "    \n",
    "    \n",
    "    confName = 'default_'+str(ident)+'.sex'\n",
    "    with open(defaultDir+confName,'w') as f:\n",
    "        f.write(data)\n",
    "    astroprov.provcall(valList,[confName],\"makeConfig_Python2Python_SQ_tmpl.provn\",\"makeConfig\",provDir)\n",
    "    return(confName,tableName,catname)\n",
    "\n",
    "\n",
    "\n",
    "def findObjects(confName,tableName,catName,provDir,defaultDir='/home/mj1e16/sextractor/sextractor-master/config/',imagename='/home/mj1e16/iraf/editedImage5000.fits'):\n",
    "    \n",
    "    astroprov.provcall([confName,'/home/mj1e16/iraf/editedImage5000.fits'],[tableName],\"findObjects_Python2DaoStarfidner_SQ_tmpl.provn\",\"findObjects\",provDir)\n",
    "\n",
    "    os.chdir(defaultDir)\n",
    "    subprocess.call(['sex',imagename,'-c',confName])\n",
    "    assoc = Table.read(catName,format='ascii.sextractor')\n",
    "    df = assoc.to_pandas()\n",
    "    df_spark = sqlContext.createDataFrame(df)\n",
    "    temptableName = tableName[0:5]+tableName[-1]\n",
    "    #print(temptableName)\n",
    "    df_spark.registerTempTable(temptableName)\n",
    "    #df_spark.write.format('jdbc').options(url='jdbc:mysql://localhost/Kepler',driver='com.mysql.jdbc.Driver',dbtable='{}'.format(tableName),user='mj1e16',password='[sqlT1G3R]').mode('append').save()\n",
    "\n",
    "    #return df\n",
    "\n",
    "def alltogethernow(valList,tableName,IMAGE,provDir):\n",
    "    Names = makeConfig(valList,provDir,tableName=tableName)\n",
    "    findObjects(Names[0],Names[1],Names[2],provDir,imagename=IMAGE) # confName tabName catname\n",
    "    innerJoin(Names[1],provDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valList = [np.linspace(1,10,10),np.linspace(1,9,9),np.linspace(8,128,16),[1,3,5,7,9,11]] # astro start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateImage(valList,simImage,provDir,smallName='Poshak',atList=['DETECT_THRESH','DETECT_MINAREA','BACK_SIZE','BACK_FILTERSIZE']):\n",
    "\n",
    "    p = ThreadPool(6)\n",
    "    t0 = time.time()\n",
    "    for x0 in range(len(valList[0])):\n",
    "        for x1 in range(len(valList[1])):\n",
    "                for x2 in range(len(valList[2])):\n",
    "                    name = smallName+'_'+str(x0)+'_'+str(x1)+'_'+str(x2)+'_'\n",
    "                    fullname = [name]*len(valList[3])\n",
    "                    fullValList = []\n",
    "                    for x3 in range(len(valList[3])):\n",
    "                        fullname[x3] += str(x3)\n",
    "                        print(fullname[x3])\n",
    "                        fullValList.append([valList[0][x0],valList[1][x1],valList[2][x2],valList[3][x3]])\n",
    "\n",
    "                        #alltogethernow(fullValList[x4],fullname,imageName,provDir)\n",
    "                    try:\n",
    "                        p.map(partial(alltogethernow,tableName=fullname,IMAGE=simImage,provDir=provDir),fullValList)\n",
    "                    except RuntimeError:\n",
    "                        with open('redos','a') as f:\n",
    "                            bigString = simImage+','+str(fullname)+','+str(fullValList)\n",
    "                            f.write(bigString)\n",
    "                        print('Redo with valList = ',fullValList)\n",
    "                        pass\n",
    "\n",
    "    #def alltogethernow(valList,tableName,IMAGE,provDir):\n",
    "\n",
    "    print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poshak_44_1_0_0_0_0\n",
      "Poshak_44_1_0_0_0_1\n",
      "Poshak_44_1_0_0_0_2\n",
      "Poshak_44_1_0_0_0_3\n",
      "Poshak_44_1_0_0_0_4\n",
      "Poshak_44_1_0_0_0_5\n"
     ]
    }
   ],
   "source": [
    "### Make function to replace starlist\n",
    "evaluateImage(valList,'/home/mj1e16/Simages/diff_44_1_alt.fits','/home/mj1e16/keplerPhotometry/provDump/44/selectiveMedian/',smallName='Poshak_44_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'aaaaa{0}aaaaa{0}'.format('b','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaaaabaaaaab'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
